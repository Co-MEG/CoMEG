{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVF3pGa35Az-"
   },
   "source": [
    "# Formal concept analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply FCA to Wikivitals to find relevant set of words (= concepts) shared by groups of articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1863,
     "status": "ok",
     "timestamp": 1576524912882,
     "user": {
      "displayName": "Pascal Bianchi",
      "photoUrl": "",
      "userId": "14431080439002320783"
     },
     "user_tz": -60
    },
    "id": "mi5Map_q5Az_",
    "outputId": "0434e570-719b-4e48-ac1d-611659e0b7c5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sknetwork.data import load_netset\n",
    "from sknetwork.utils import get_degrees, get_membership\n",
    "from sknetwork.ranking import top_k\n",
    "from sknetwork.topology import Triangles, Cliques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVF3pGa35Az-"
   },
   "source": [
    "## Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing files...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "wikivitals = load_netset('wikivitals+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = wikivitals.adjacency\n",
    "biadjacency = wikivitals.biadjacency\n",
    "names = wikivitals.names\n",
    "words = wikivitals.names_col\n",
    "labels = wikivitals.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<45179x85512 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4786126 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biadjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['mixture', 'directly'], dtype='<U26'),\n",
       " array([ 616, 4060], dtype=int32))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = biadjacency[0].indices[:2]\n",
    "words[indexes], indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Law of mass action', 'Diesel engine', 'Fructose', 'Lidocaine',\n",
       "       'Lithography', 'Matthew Quintal', 'Ned Young', 'Oil shale',\n",
       "       'Reaction intermediate', 'Sand casting', 'Soft drink',\n",
       "       'Solubility', 'Vermicompost', 'William McCoy (mutineer)'],\n",
       "      dtype='<U85')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_biadj = biadjacency.astype(bool)\n",
    "obj = np.flatnonzero(bool_biadj[:, indexes].dot(np.ones(len(indexes))) == len(indexes))\n",
    "names[obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Law of mass action\n",
      "['mixture' 'directly' 'concept' 'proposition' 'datum' 'proportional'\n",
      " 'rate' 'stem' 'that' 'research' 'two' 'ratio' 'to' 'action' 'backward'\n",
      " 'between' 'recognize' 'elementary' 'constant' 'an' 'independently' 'for'\n",
      " 'both' 'equal' 'mass' 'Cato' 'law' 'composition' 'or' 'they' 'reactant'\n",
      " 'aspect' 'process' 'and' 't' 'product' 'involve' 'give' 'Jacobus'\n",
      " 'Henricus' 'thermodynamic' 'equation' 'expression' 'modern' 'statement'\n",
      " 'by' 'equilibrium' 'derive' 'perform' 'specifically' 'initial' 'this'\n",
      " 'Guldberg' 'kinetic' 'Hoff' 'it' 'propose' 'predict' 'in' 'later'\n",
      " 'quantity' 'chemical' 'from' 'explain' 'can' 'be' 'van' 'with' 'concern'\n",
      " 'a' 'concentration' 'solution' 'dynamic' 'potential' 'rediscover'\n",
      " 'reaction' 'of' 'Peter' 'about' 'forward' 'characterize' 'order' 'have'\n",
      " 'which' 'chemistry' 'formulation' 'must' 'behavior' 'also' 'at' 'Waage'\n",
      " 'appealing' 'imply' 'activity' 'use' 'the']\n"
     ]
    }
   ],
   "source": [
    "print(names[0])\n",
    "print(words[biadjacency[0].indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interest of concept  \n",
    "\n",
    "> \"An event is unexpected if it is simpler (=less complex) to describe than to generate.\" (Simplicity theory)\n",
    "\n",
    "- unexpectedness $U = C_w - C$, with $C_w$ the complexity to generate situation and $C$ the description complexity\n",
    "- here complexity is the minimal description\n",
    "- we can compute amount of information received for each subset of attributes in $A$, $I(X)=\\text{log}_2(\\dfrac{1}{\\prod_i p_i(x)})$, with $X \\subseteq A$ and $x \\in X$  \n",
    "- description complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['blue', 'brown', 'cat', 'dog', 'eat', 'fox', 'the'], dtype='<U5'),\n",
       " array([ 6,  3,  1,  2,  2,  1, 11]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = ['the', 'brown', 'fox', 'the', 'eat', 'brown', 'dog', 'the', 'the', 'the', 'the',\n",
    "         'dog', 'the', 'the', 'the', 'the', 'blue', 'blue', 'the', 'eat', 'brown', 'cat', 'blue', 'blue', 'blue', 'blue']\n",
    "words, counts = np.unique(corpus, return_counts=True)\n",
    "words, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue': 6, 'brown': 3, 'cat': 1, 'dog': 2, 'eat': 2, 'fox': 1, 'the': 11}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {}\n",
    "for i, j in zip(words, counts):\n",
    "    d[i]=j\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.400879436282183\n",
      "\n",
      "words: ['blue' 'eat'] - c: 0.103 - u: 9.29764\n",
      "words: ['brown' 'eat'] - c: 0.060 - u: 9.34038\n",
      "words: ['blue' 'brown'] - c: 0.139 - u: 9.26159\n",
      "words: ['the' 'the'] - c: 0.525 - u: 8.87584\n",
      "words: ['blue' 'dog'] - c: 0.103 - u: 9.29764\n",
      "words: ['eat' 'blue'] - c: 0.103 - u: 9.29764\n",
      "words: ['fox' 'eat'] - c: 0.025 - u: 9.37602\n",
      "words: ['the' 'cat'] - c: 0.097 - u: 9.30420\n",
      "words: ['blue' 'fox'] - c: 0.060 - u: 9.34038\n",
      "words: ['cat' 'cat'] - c: 0.181 - u: 9.22009\n",
      "words: ['dog' 'blue'] - c: 0.103 - u: 9.29764\n",
      "words: ['dog' 'the'] - c: 0.161 - u: 9.24006\n",
      "words: ['cat' 'brown'] - c: 0.035 - u: 9.36619\n",
      "words: ['the' 'dog'] - c: 0.161 - u: 9.24006\n",
      "words: ['the' 'cat'] - c: 0.097 - u: 9.30420\n",
      "words: ['eat' 'the'] - c: 0.161 - u: 9.24006\n",
      "words: ['brown' 'cat'] - c: 0.035 - u: 9.36619\n",
      "words: ['fox' 'fox'] - c: 0.181 - u: 9.22009\n",
      "words: ['fox' 'the'] - c: 0.097 - u: 9.30420\n",
      "words: ['blue' 'dog'] - c: 0.103 - u: 9.29764\n",
      "('fox', 'eat') 9.376024763393774\n",
      "('cat', 'brown') 9.366193414378806\n",
      "('brown', 'cat') 9.366193414378806\n",
      "('brown', 'eat') 9.3403831321204\n",
      "('blue', 'fox') 9.3403831321204\n"
     ]
    }
   ],
   "source": [
    "def gen_complexity(N, k):\n",
    "    return np.log2(N**k)\n",
    "\n",
    "def desc_complexity(probs):\n",
    "    res = 1\n",
    "    for i in probs:\n",
    "        res *= i\n",
    "    return res * np.log2(1 / (res))\n",
    "\n",
    "\n",
    "res_vals = {}\n",
    "combs = []\n",
    "cpt = 0\n",
    "N = np.sum(counts)\n",
    "cw = gen_complexity(N, 2)\n",
    "print(cw)\n",
    "print()\n",
    "for i in range(20):\n",
    "    ws = np.random.choice(words, 2)\n",
    "    res = 1\n",
    "    if len(np.unique(ws)) > 1:\n",
    "        for w in ws:\n",
    "            res *= d.get(w) / N\n",
    "    else:\n",
    "        res = d.get(ws[0]) / N\n",
    "    c = desc_complexity([res])\n",
    "    u = cw - c\n",
    "    print(f'words: {ws} - c: {c:.3f} - u: {(cw - c):.5f}')\n",
    "    if tuple(ws) not in combs:\n",
    "        combs.append(tuple(ws))\n",
    "        res_vals[cpt] = u\n",
    "        cpt += 1\n",
    "        \n",
    "sorted_list = sorted(res_vals.items(), key=lambda x: x[1], reverse=True)\n",
    "for idx, t in enumerate(sorted_list):\n",
    "    if idx < 5:\n",
    "        print(combs[t[0]], t[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We succeed in findings the most unexpected sets of attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm?**  \n",
    "Etant donné un graphe attribué $G=(V, E, A)$\n",
    "- démarrer à partir d'un sous graphe $g_0$ (lequel? k-core, connected compo, clique ...)\n",
    "- ajouter des noeuds $v \\in V$ 1 à 1 et\n",
    "    - calculer la closure, i.e le sous ensemble d'attributes, des noeuds du sous-graphe constitué $V(g_i)^{\\prime}=X \\in A$\n",
    "    - calculer la surprise (unexpedctness $U$) de cette closure $U(X)$. $U$ peut etre calculé en utilisant les fréquences d'apparition des attributs dans X.\n",
    "    - si la surprise augmente avec le noeud ajouté, on le garde. Sinon on cherche un autre noeud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = biadjacency > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<45179x85512 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 4786126 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concepts(context, n_concepts = 5000, n_objects_max = 1000, n_objects_min = 10, depth = 5):\n",
    "    \"\"\"Get concepts by FCA.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    context : sparse matrix\n",
    "        Matrix object x attribute.\n",
    "    n_concepts : int\n",
    "        Maximum number of concepts per level (except top level).\n",
    "    n_objects_max : int\n",
    "        Maximum number of objects per attribute (frequent attributes are discarded).\n",
    "    n_objects_min : int\n",
    "        Minimum number of objects per attribute (rare attributes are discarded).\n",
    "    depth : int\n",
    "        Depth of the hierarchy\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    index_attribute : np.ndarray\n",
    "        Index of attributes.\n",
    "    concept_attribute : sparse matrix\n",
    "        Matrix concept x attributes.\n",
    "    concept_object : sparse matrix\n",
    "        Matrix concept x object.\n",
    "    \"\"\"\n",
    "    n_objects, n_attributes = context.shape\n",
    "\n",
    "    # select attributes\n",
    "    freq_attribute = get_degrees(context, transpose=True)\n",
    "    index = np.flatnonzero((freq_attribute <= n_objects_max) & (freq_attribute >= n_objects_min))\n",
    "    attribute = sparse.identity(n_attributes).tocsr()[index]\n",
    "    n_attributes = len(index)\n",
    "    concept_attribute = sparse.identity(n_attributes).tocsr()\n",
    "    concept_object = context.T.tocsr()[index]\n",
    "    freq_attribute = freq_attribute[index]\n",
    "    index_attribute = index.copy()\n",
    "    \n",
    "    # simple concepts (= single attribute)\n",
    "    simple_concept_attribute = concept_attribute.copy()\n",
    "    simple_concept_object = concept_object.copy()\n",
    "    simple_concept_freq = freq_attribute.copy()\n",
    "\n",
    "    # current concepts (= simple concepts to start)\n",
    "    current_concept_attribute = concept_attribute.copy()\n",
    "    current_concept_object = concept_object.copy()\n",
    "    current_concept_freq = freq_attribute.copy()\n",
    "\n",
    "    for t in range(1, depth):\n",
    "\n",
    "        # add attribute\n",
    "        concept_count = current_concept_object.astype(int).dot(simple_concept_object.T).tocoo()\n",
    "        row = concept_count.row\n",
    "        col = concept_count.col\n",
    "        count = concept_count.data\n",
    "\n",
    "        # score concepts\n",
    "        scores = np.minimum(current_concept_freq[row] - count, simple_concept_freq[col] - count)\n",
    "        scores = np.minimum(scores, count)\n",
    "        scores = scores * (scores >= n_objects_min)\n",
    "\n",
    "        # select concepts\n",
    "        index = top_k(scores, n_concepts)\n",
    "        concept_attribute_ = sparse.lil_matrix((n_concepts, n_attributes), dtype=bool)\n",
    "        concept_ids = current_concept_attribute[row[index]].indices\n",
    "        attribute_ids = simple_concept_attribute[col[index]].indices\n",
    "        row_ = np.repeat(np.arange(len(index)), t + 1)\n",
    "        col_ = np.hstack((concept_ids.reshape(-1, t), attribute_ids.reshape(-1, 1))).ravel()\n",
    "        concept_attribute_[row_, col_] = 1\n",
    "        concept_attribute_ = concept_attribute_.tocsr()\n",
    "\n",
    "        # remove duplicates\n",
    "        _, index_ = np.unique(concept_attribute_.indices.reshape(-1, t + 1), axis=0, return_index=True)\n",
    "        concept_attribute_ = concept_attribute_[index_]\n",
    "        index = index[index_]\n",
    "\n",
    "        # count objects\n",
    "        concept_object_ = current_concept_object[row[index]].minimum(simple_concept_object[col[index]])\n",
    "        concept_object_.eliminate_zeros()\n",
    "        concept_freq_ = get_degrees(concept_object_)\n",
    "\n",
    "        # update \n",
    "        concept_attribute = sparse.vstack((concept_attribute, concept_attribute_))\n",
    "        concept_object = sparse.vstack((concept_object, concept_object_))\n",
    "\n",
    "        current_concept_attribute = concept_attribute_.copy()\n",
    "        current_concept_object = concept_object_.copy()\n",
    "        current_concept_freq = concept_freq_.copy()\n",
    "    \n",
    "    return index_attribute, concept_attribute, concept_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.71 s, sys: 599 ms, total: 3.31 s\n",
      "Wall time: 3.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index_attribute, concept_attribute, concept_object = get_concepts(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_attribute = words[index_attribute]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<36320x45179 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 2679756 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<36320x24282 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 68148 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_freq = get_degrees(concept_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_concept = get_degrees(concept_attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths, counts = np.unique(length_concept, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24282  2517  2784  3205  3532]\n"
     ]
    }
   ],
   "source": [
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<36320x24282 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 68148 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Length 2\n",
      "['port' 'metropolitan'] 128\n",
      "['metropolitan' 'growth'] 92\n",
      "['League' 'victory'] 94\n",
      "['al' 'Ali'] 84\n",
      "['sound' 'band'] 155\n",
      "['studio' 'Billboard'] 143\n",
      "['observation' 'observe'] 84\n",
      "['Olympics' 'athlete'] 141\n",
      "['astronomical' 'planet'] 87\n",
      "['Ocean' 'settlement'] 86\n",
      "-----\n",
      "Length 3\n",
      "['League' 'Champions' 'Cup'] 75\n",
      "['tour' 'band' 'induct'] 78\n",
      "['hit' 'Grammy' 'you'] 66\n",
      "['Sciences' 'economist' 'Nobel'] 67\n",
      "['hit' 'chart' 'songwriter'] 79\n",
      "['UNESCO' 'populous' 'Heritage'] 64\n",
      "['nomination' 'Film' 'accolade'] 58\n",
      "['gold' 'retire' 'medal'] 84\n",
      "['Olympics' 'bronze' 'medal'] 66\n",
      "['Grammy' 'songwriter' 'induct'] 54\n",
      "-----\n",
      "Length 4\n",
      "['symptom' 'risk' 'disease' 'factor'] 42\n",
      "['album' 'Rock' 'induct' 'Music'] 51\n",
      "['album' 'Roll' 'Rock' 'guitar'] 57\n",
      "['sale' 'album' 'certify' 'Billboard'] 37\n",
      "['album' 'pop' 'recording' 'songwriter'] 45\n",
      "['hit' 'pop' 'Hot' 'Billboard'] 46\n",
      "['album' 'Grammy' 'Top' 'Music'] 39\n",
      "['symptom' 'medication' 'blood' 'diagnosis'] 38\n",
      "['album' 'Records' 'tour' 'band'] 51\n",
      "['album' 'studio' 'Billboard' 'songwriter'] 65\n",
      "-----\n",
      "Length 5\n",
      "['album' 'solo' 'Roll' 'Rock' 'Billboard'] 27\n",
      "['love' 'album' 'Grammy' 'Billboard' 'you'] 31\n",
      "['album' 'Stone' 'chart' 'Grammy' 'Time'] 36\n",
      "['album' 'week' 'chart' 'Billboard' 'Time'] 26\n",
      "['album' 'week' 'studio' 'chart' 'Billboard'] 37\n",
      "['album' 'musician' 'Rock' 'band' 'induct'] 43\n",
      "['album' 'chart' 'Rock' 'tour' 'induct'] 33\n",
      "['club' 'League' 'Player' 'FIFA' 'football'] 26\n",
      "['album' 'chart' 'Grammy' 'songwriter' 'you'] 36\n",
      "['student' 'faculty' 'graduate' 'Association' 'university'] 27\n"
     ]
    }
   ],
   "source": [
    "# some concepts\n",
    "for t in range(1, depth):\n",
    "    length = t + 1\n",
    "    print('-----')\n",
    "    print('Length', length)\n",
    "    index = np.flatnonzero(length_concept==length)\n",
    "    for i in np.random.choice(index, size=10):\n",
    "        print(names_attribute[concept_attribute[i].indices], concept_freq[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "Length 2\n",
      "['hit' 'chart'] 200\n",
      "['...Baby One More Time (song)' '2NE1' 'A-ha' 'ABBA' 'AC/DC'\n",
      " 'Adult contemporary music' 'Aerosmith' 'Akon' 'Alabama (band)'\n",
      " 'Alice in Chains' 'Alizée' 'All You Need Is Love' 'American Pie (song)'\n",
      " 'Amy Grant' 'Andrea Bocelli' 'Anita Bryant' 'Are You Experienced'\n",
      " 'Ayumi Hamasaki' 'Backstreet Boys' 'Bananarama']\n",
      "-----\n",
      "Length 3\n",
      "['hit' 'studio' 'songwriter'] 64\n",
      "['Akon' 'Anitta (singer)' 'Astral Weeks' 'Ayumi Hamasaki' 'Barry White'\n",
      " 'Bette Midler' 'Beyoncé' 'Billie Eilish' 'Billy Joel' 'Blonde on Blonde'\n",
      " 'Bob Marley' 'Brian Wilson' 'Bruce Springsteen' 'Bruno Mars'\n",
      " 'Buddy Holly' 'Carrie Underwood' 'Cat Stevens'\n",
      " 'Crosby, Stills, Nash & Young' 'Cyndi Lauper' 'Daddy Yankee']\n",
      "-----\n",
      "Length 4\n",
      "['album' 'chart' 'Billboard' 'Top'] 56\n",
      "['Akon' 'Alicia Keys' 'Are You Experienced' 'BTS' 'Bananarama'\n",
      " 'Calvin Harris' 'Cardi B' 'Carly Simon' 'Carrie Underwood' 'Def Leppard'\n",
      " 'Dolly Parton' 'Donna Summer' 'Donovan' 'Dusty Springfield'\n",
      " 'Gloria Estefan' 'Imagine (John Lennon song)' 'J Balvin' 'James Brown'\n",
      " 'Janet Jackson' 'Jenni Rivera']\n",
      "-----\n",
      "Length 5\n",
      "['album' 'hit' 'studio' 'band' 'induct'] 29\n",
      "[\"(I Can't Get No) Satisfaction\" 'Blonde on Blonde' 'Blondie (band)'\n",
      " 'Bob Marley' 'Bruce Springsteen' 'Buddy Holly'\n",
      " 'Crosby, Stills, Nash & Young' 'Def Leppard' 'Eagles (band)'\n",
      " 'Exile on Main St.' 'Fleetwood Mac' 'Genesis (band)' 'Good Vibrations'\n",
      " \"Guns N' Roses\" 'Jimi Hendrix' 'Midnight Oil' 'Nightwish'\n",
      " 'Nirvana (band)' 'Pink Floyd' 'R.E.M.']\n"
     ]
    }
   ],
   "source": [
    "# a concept and its objects\n",
    "for t in range(1, depth):\n",
    "    length = t + 1\n",
    "    print('-----')\n",
    "    print('Length', length)\n",
    "    index = np.flatnonzero(length_concept==length)\n",
    "    i = np.random.choice(index)\n",
    "    print(names_attribute[concept_attribute[i].indices], concept_freq[i])\n",
    "    objects = concept_object[i].indices[:20]\n",
    "    print(names[objects])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coat of arms of the Republic of Albania\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# an object and its concepts\n",
    "i = np.random.choice(concept_object.shape[1])\n",
    "print(names[i])\n",
    "print()\n",
    "concepts = np.flatnonzero(concept_object[:, i].toarray().ravel() * (length_concept > 1))\n",
    "if len(concepts) > 10:\n",
    "    concepts = np.random.choice(concepts, size=10, replace=False)\n",
    "for j in concepts:\n",
    "    print(names_attribute[concept_attribute[j].indices], concept_freq[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<36320x24282 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 68148 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter concept that have > 1 attribute inside their intent\n",
    "concept_size = get_degrees(concept_attribute)\n",
    "mask = concept_size > 1\n",
    "big_concept_attribute = concept_attribute[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12038x24282 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 43866 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_concept_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_concept_object = concept_object[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12038x45179 sparse matrix of type '<class 'numpy.bool_'>'\n",
       "\twith 746323 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_concept_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build corpus made of concepts, i.e each concept intent is considered to be a sentence in the Word2Vec model.  \n",
    "Train a Word2Vec model to get embedding for each word in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['victim', 'crime'] ['leadership', 'victory']\n"
     ]
    }
   ],
   "source": [
    "# Build corpus for w2v\n",
    "n_rows = big_concept_attribute.shape[0]\n",
    "corpus = []\n",
    "for row in range(n_rows):\n",
    "    corpus.append(names_attribute[big_concept_attribute[row].indices].tolist())\n",
    "print(corpus[0], corpus[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=corpus, min_count=1, window=2, vector_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedd each concept by computing the average word embedding it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concept embedding as average of their intent word embeddings\n",
    "concept_embs = np.zeros((n_rows, 100))\n",
    "\n",
    "for idx, row in enumerate(big_concept_attribute):\n",
    "    names_attrs = names_attribute[row.indices]\n",
    "    concept_embs[idx, :] = np.mean(model.wv[names_attrs], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12038, 100)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept_embs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cosine similarity between concept embeddings.  \n",
    "\n",
    "The goal is to create a matrix of distances between concepts, which will be used in a solver to select top-$k$ concepts that have the greater pairwise distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.61 s, sys: 75.4 ms, total: 4.69 s\n",
      "Wall time: 4.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import random\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "cosine_sim_scipy = pdist(concept_embs, 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 226 ms, sys: 303 ms, total: 530 ms\n",
      "Wall time: 794 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "square_dists = squareform(cosine_sim_scipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.01314337, 0.01136182, 0.01087863, 0.0120954 ],\n",
       "       [0.01314337, 0.        , 0.00371603, 0.00358535, 0.00413979],\n",
       "       [0.01136182, 0.00371603, 0.        , 0.00071358, 0.00134886],\n",
       "       [0.01087863, 0.00358535, 0.00071358, 0.        , 0.0011948 ],\n",
       "       [0.0120954 , 0.00413979, 0.00134886, 0.0011948 , 0.        ]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_dists[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 185 ms, sys: 122 ms, total: 307 ms\n",
      "Wall time: 429 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "row, col = np.triu_indices(concept_embs.shape[0], k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 82.1 ms, sys: 259 ms, total: 341 ms\n",
      "Wall time: 454 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = concept_embs.shape[0]\n",
    "sparse_dists = sparse.coo_matrix((cosine_sim_scipy, (row, col)), shape=(n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 373 ms, sys: 246 ms, total: 618 ms\n",
      "Wall time: 815 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "csr_sparse_dists = sparse_dists.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66.5 ms, sys: 67.7 ms, total: 134 ms\n",
      "Wall time: 156 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dense_dists = sparse_dists.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12038, 12038)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.01314337, 0.01136182, 0.01087863, 0.0120954 ],\n",
       "        [0.        , 0.        , 0.00371603, 0.00358535, 0.00413979],\n",
       "        [0.        , 0.        , 0.        , 0.00071358, 0.00134886],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.0011948 ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_dists[:5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['guitarist' 'Roll']\n",
      "['guitarist' 'Rock']\n",
      "Cosine sim of average embeddings:  0.9812906\n",
      "cosine scipy distance:  0.01870948703907327\n",
      "['guitarist' 'Roll']\n",
      "['tour' 'you']\n",
      "Cosine sim of average embeddings:  0.95490575\n",
      "cosine scipy distance:  0.04509436693487745\n",
      "['optical']\n",
      "['guitarist' 'Roll']\n",
      "Cosine sim of average embeddings:  0.07595989\n",
      "cosine scipy distance:  0.9240401075130381\n"
     ]
    }
   ],
   "source": [
    "# Verification of distance between concept embeddings\n",
    "# 2 concept embedding should be distant in the embedding space if they contain words that are semantically differents\n",
    "# We see that the embedding space respects this criterion\n",
    "\n",
    "print(names_attribute[concept_attribute[24586, :].indices])\n",
    "print(names_attribute[concept_attribute[24588, :].indices])\n",
    "\n",
    "a = np.mean([model.wv['guitarist'], model.wv['Rock']], axis=0)\n",
    "b = np.mean([model.wv['guitarist'], model.wv['Roll']], axis=0)\n",
    "print('Cosine sim of average embeddings: ', cosine_similarity(a, b))\n",
    "\n",
    "#print('old cosine: ', cosine_sim[24586, 24588])\n",
    "print('cosine scipy distance: ', dense_dists[24586, 24588])\n",
    "\n",
    "\n",
    "print(names_attribute[concept_attribute[24586, :].indices])\n",
    "print(names_attribute[concept_attribute[26561, :].indices]) # ['tour' 'you']\n",
    "\n",
    "a = np.mean([model.wv['guitarist'], model.wv['Roll']], axis=0)\n",
    "b = np.mean([model.wv['tour'], model.wv['you']], axis=0)\n",
    "print('Cosine sim of average embeddings: ', cosine_similarity(a, b))\n",
    "\n",
    "print('cosine scipy distance: ', dense_dists[24586, 26561])\n",
    "\n",
    "\n",
    "print(names_attribute[concept_attribute[100, :].indices])\n",
    "print(names_attribute[concept_attribute[24586, :].indices]) # ['tour' 'you']\n",
    "\n",
    "a = model.wv['optical']\n",
    "b = np.mean([model.wv['guitarist'], model.wv['Roll']], axis=0)\n",
    "print('Cosine sim of average embeddings: ', cosine_similarity(a, b))\n",
    "\n",
    "print('cosine scipy distance: ', dense_dists[100, 24586])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old manner to compute pairwise similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD\n",
    "def cosine_similarity(c1, c2):\n",
    "    return c1.dot(c2) / (np.linalg.norm(c1) * np.linalg.norm(c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD\n",
    "# Cosine similarity between embeddings\n",
    "cosine_sim = concept_embs.dot(concept_embs.T)\n",
    "cosine_sim = \n",
    "cosine_dist = 1 - cosine_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize a solver to find the top-$k$ concepts that maximize their pairwise distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/simondelarue/Documents/PhD/Research/Envs/COMEG/lib/python3.9/site-packages/pulp/apis/../solverdir/cbc/osx/64/cbc /var/folders/hb/p2nvp7cj1dg6y96zlm9vqb2c0000gn/T/b716c9ea68f445e483fba050af476c79-pulp.mps max timeMode elapsed branch printingOptions all solution /var/folders/hb/p2nvp7cj1dg6y96zlm9vqb2c0000gn/T/b716c9ea68f445e483fba050af476c79-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 6 COLUMNS\n",
      "At line 48159 RHS\n",
      "At line 48161 BOUNDS\n",
      "At line 60200 ENDATA\n",
      "Problem MODEL has 1 rows, 12038 columns and 12038 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "9038 slacks added\n",
      "using 1 columns not 3000\n",
      "12037 slacks added\n",
      "Continuous objective value is 6.96435e+06 - 0.23 seconds\n",
      "Cgl0004I processed model has 1 rows, 12038 columns (12038 integer (12038 of which binary)) and 12038 elements\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
      "Cbc0038I Solution found of -6.96435e+06\n",
      "Cbc0038I Before mini branch and bound, 12038 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (1.54 seconds)\n",
      "Cbc0038I After 1.54 seconds - Feasibility pump exiting with objective of -6.96435e+06 - took 0.01 seconds\n",
      "Cbc0012I Integer solution of -6964348.4 found by feasibility pump after 0 iterations and 0 nodes (1.54 seconds)\n",
      "Cbc0001I Search completed - best objective -6964348.441420768, took 0 iterations and 0 nodes (1.54 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from -6.96435e+06 to -6.96435e+06\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                6964348.44142077\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             1.52\n",
      "Time (Wallclock seconds):       1.55\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       1.54   (Wallclock seconds):       1.58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Optimization solver\n",
    "import pulp\n",
    "\n",
    "def solver(matrix, concept_attribute, k):\n",
    "    idx = np.arange(0, matrix.shape[0])\n",
    "    x = pulp.LpVariable.dicts(\"x\", \n",
    "                        indices = idx, \n",
    "                        lowBound=0, upBound=1, \n",
    "                        cat='Integer', indexStart=[])\n",
    "\n",
    "    prob = pulp.LpProblem(\"clustering\", pulp.LpMaximize)\n",
    "    prob += pulp.lpSum([x[i] * matrix[i].sum() * len(concept_attribute[i].indices / 5) for i in x])\n",
    "    #prob += pulp.lpSum([x[i] * matrix[i].sum()  for i in x])\n",
    "    prob += pulp.lpSum([x[i] for i in idx]) <= k    \n",
    "    prob.solve()\n",
    "    return prob\n",
    "    \n",
    "#prob = solver(cosine_dist, 10000)\n",
    "#prob = solver(dense_dists, concept_attribute, 5000)\n",
    "prob = solver(square_dists, concept_attribute, 1000)\n",
    "\n",
    "useful_concepts = np.array([int(v.name.split('_')[1]) for v in prob.variables() if v.varValue > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i = 34069 - red hot chili peppers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of concepts related to 34069:  171\n"
     ]
    }
   ],
   "source": [
    "print('Number of concepts related to 34069: ', len(concepts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Distribution of number of interesting concepts per object\n",
    "plt.hist(big_concept_object[useful_concepts].T.dot(np.ones(len(useful_concepts))), bins=1000)\n",
    "plt.xlim(0, 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of number of object per interesting concept \n",
    "plt.hist(big_concept_object[useful_concepts].dot(np.ones(big_concept_object.shape[1])), bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Painted Desert (Arizona) 30778\n",
      "\n",
      "New method\n",
      "\n",
      "old method\n",
      "['color' 'red'] 195 26568\n"
     ]
    }
   ],
   "source": [
    "# an object and its concepts\n",
    "i = np.random.choice(big_concept_object.shape[1])\n",
    "#i = 34069\n",
    "print(names[i], i)\n",
    "print()\n",
    "print('New method')\n",
    "concepts = np.flatnonzero(big_concept_object[useful_concepts][:, i].toarray().ravel() * (length_concept[useful_concepts] >= 1))\n",
    "#if len(concepts) > 10:\n",
    "#    concepts = np.random.choice(concepts, size=20, replace=False)\n",
    "for j in concepts:\n",
    "    print(names_attribute[big_concept_attribute[useful_concepts][j].indices], j)\n",
    "    \n",
    "print()\n",
    "print(f'old method')\n",
    "concepts = np.flatnonzero(concept_object[:, i].toarray().ravel() * (length_concept > 1))\n",
    "\n",
    "for j in concepts:\n",
    "    print(names_attribute[concept_attribute[j].indices], concept_freq[j], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2304"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of objects explained by 1 ore more concepts\n",
    "len(np.flatnonzero(big_concept_object[useful_concepts].T.dot(np.ones(1000))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eric Heiden 12682\n",
      "\n",
      "New method\n",
      "['Olympic' 'Games' 'athlete'] 237\n",
      "['Olympic' 'Games'] 622\n",
      "['Olympic' 'athlete'] 623\n",
      "['Games' 'athlete'] 919\n",
      "\n",
      "old method\n",
      "['Olympics' 'Olympic'] 180 24330\n",
      "['Olympics' 'Games'] 177 24331\n",
      "['Olympics' 'gold'] 223 24333\n",
      "['Olympics' 'athlete'] 141 24336\n",
      "['Olympics' 'olympic'] 208 24337\n",
      "['Olympics' 'medal'] 250 24340\n",
      "['Olympics' 'Winter'] 119 24341\n",
      "['Olympics' 'competition'] 112 24344\n",
      "['Olympic' 'Games'] 244 24928\n",
      "['Olympic' 'gold'] 147 24929\n",
      "['Olympic' 'athlete'] 124 24930\n",
      "['Olympic' 'olympic'] 157 24931\n",
      "['Olympic' 'medal'] 159 24934\n",
      "['Olympic' 'competition'] 102 24936\n",
      "['Games' 'gold'] 136 25196\n",
      "['Games' 'athlete'] 106 25197\n",
      "['Games' 'olympic'] 134 25198\n",
      "['Games' 'medal'] 152 25200\n",
      "['Games' 'competition'] 103 25202\n",
      "['gold' 'athlete'] 115 25921\n",
      "['gold' 'olympic'] 232 25922\n",
      "['gold' 'medal'] 316 25924\n",
      "['speed' 'distance'] 111 26409\n",
      "['athlete' 'olympic'] 149 26438\n",
      "['athlete' 'medal'] 136 26440\n",
      "['athlete' 'competition'] 85 26442\n",
      "['olympic' 'medal'] 248 26669\n",
      "['olympic' 'competition'] 97 26672\n",
      "['Olympics' 'Olympic' 'Games'] 127 26818\n",
      "['Olympics' 'Olympic' 'gold'] 105 26819\n",
      "['Olympics' 'Olympic' 'athlete'] 78 26820\n",
      "['Olympics' 'Olympic' 'olympic'] 105 26821\n",
      "['Olympics' 'Olympic' 'medal'] 114 26824\n",
      "['Olympics' 'Olympic' 'Winter'] 60 26825\n",
      "['Olympics' 'Olympic' 'competition'] 55 26828\n",
      "['Olympics' 'Games' 'gold'] 94 26829\n",
      "['Olympics' 'Games' 'athlete'] 70 26830\n",
      "['Olympics' 'Games' 'olympic'] 91 26831\n",
      "['Olympics' 'Games' 'medal'] 107 26833\n",
      "['Olympics' 'Games' 'Winter'] 59 26834\n",
      "['Olympics' 'Games' 'competition'] 59 26837\n",
      "['Olympics' 'gold' 'athlete'] 88 26845\n",
      "['Olympics' 'gold' 'olympic'] 146 26846\n",
      "['Olympics' 'gold' 'medal'] 206 26849\n",
      "['Olympics' 'gold' 'Winter'] 57 26850\n",
      "['Olympics' 'gold' 'competition'] 57 26853\n",
      "['Olympics' 'athlete' 'olympic'] 98 26860\n",
      "['Olympics' 'athlete' 'medal'] 105 26862\n",
      "['Olympics' 'athlete' 'competition'] 50 26864\n",
      "['Olympics' 'olympic' 'medal'] 160 26867\n",
      "['Olympics' 'olympic' 'Winter'] 53 26868\n",
      "['Olympics' 'olympic' 'competition'] 66 26870\n",
      "['Olympics' 'medal' 'Winter'] 60 26876\n",
      "['Olympics' 'medal' 'competition'] 65 26880\n",
      "['Olympic' 'Games' 'gold'] 104 27642\n",
      "['Olympic' 'Games' 'athlete'] 91 27643\n",
      "['Olympic' 'Games' 'olympic'] 108 27644\n",
      "['Olympic' 'Games' 'medal'] 117 27647\n",
      "['Olympic' 'Games' 'Winter'] 66 27648\n",
      "['Olympic' 'Games' 'competition'] 74 27651\n",
      "['Olympic' 'gold' 'athlete'] 69 27654\n",
      "['Olympic' 'gold' 'olympic'] 99 27655\n",
      "['Olympic' 'gold' 'medal'] 133 27657\n",
      "['Olympic' 'athlete' 'olympic'] 73 27659\n",
      "['Olympic' 'athlete' 'medal'] 78 27661\n",
      "['Olympic' 'olympic' 'medal'] 102 27664\n",
      "['Olympic' 'olympic' 'competition'] 52 27665\n",
      "['Games' 'gold' 'athlete'] 60 28305\n",
      "['Games' 'gold' 'olympic'] 83 28306\n",
      "['Games' 'gold' 'medal'] 126 28308\n",
      "['Games' 'athlete' 'olympic'] 65 28310\n",
      "['Games' 'athlete' 'medal'] 69 28312\n",
      "['Games' 'athlete' 'competition'] 51 28313\n",
      "['Games' 'olympic' 'medal'] 93 28315\n",
      "['Games' 'olympic' 'competition'] 51 28316\n",
      "['Games' 'medal' 'competition'] 52 28320\n",
      "['overall' 'gold' 'medal'] 58 28462\n",
      "['gold' 'athlete' 'olympic'] 89 29035\n",
      "['gold' 'athlete' 'medal'] 110 29037\n",
      "['gold' 'olympic' 'medal'] 208 29040\n",
      "['gold' 'olympic' 'competition'] 54 29043\n",
      "['gold' 'medal' 'Winter'] 61 29046\n",
      "['gold' 'medal' 'competition'] 62 29050\n",
      "['athlete' 'olympic' 'medal'] 104 29420\n",
      "['olympic' 'medal' 'competition'] 59 29557\n",
      "['Olympics' 'Olympic' 'Games' 'gold'] 71 29590\n",
      "['Olympics' 'Olympic' 'Games' 'athlete'] 61 29591\n",
      "['Olympics' 'Olympic' 'Games' 'olympic'] 73 29592\n",
      "['Olympics' 'Olympic' 'Games' 'medal'] 80 29595\n",
      "['Olympics' 'Olympic' 'Games' 'Winter'] 49 29596\n",
      "['Olympics' 'Olympic' 'Games' 'competition'] 45 29599\n",
      "['Olympics' 'Olympic' 'gold' 'athlete'] 54 29601\n",
      "['Olympics' 'Olympic' 'gold' 'olympic'] 78 29602\n",
      "['Olympics' 'Olympic' 'gold' 'medal'] 99 29604\n",
      "['Olympics' 'Olympic' 'athlete' 'olympic'] 56 29607\n",
      "['Olympics' 'Olympic' 'athlete' 'medal'] 61 29609\n",
      "['Olympics' 'Olympic' 'olympic' 'medal'] 82 29612\n",
      "['Olympics' 'Olympic' 'olympic' 'competition'] 40 29613\n",
      "['Olympics' 'Olympic' 'medal' 'Winter'] 36 29618\n",
      "['Olympics' 'Games' 'gold' 'athlete'] 47 29621\n",
      "['Olympics' 'Games' 'gold' 'olympic'] 65 29622\n",
      "['Olympics' 'Games' 'gold' 'medal'] 90 29624\n",
      "['Olympics' 'Games' 'gold' 'competition'] 36 29625\n",
      "['Olympics' 'Games' 'athlete' 'olympic'] 51 29628\n",
      "['Olympics' 'Games' 'athlete' 'medal'] 53 29630\n",
      "['Olympics' 'Games' 'olympic' 'medal'] 73 29632\n",
      "['Olympics' 'Games' 'olympic' 'competition'] 41 29634\n",
      "['Olympics' 'Games' 'medal' 'competition'] 41 29640\n",
      "['Olympics' 'overall' 'gold' 'medal'] 46 29641\n",
      "['Olympics' 'gold' 'athlete' 'olympic'] 69 29659\n",
      "['Olympics' 'gold' 'athlete' 'medal'] 85 29661\n",
      "['Olympics' 'gold' 'olympic' 'medal'] 137 29664\n",
      "['Olympics' 'gold' 'olympic' 'Winter'] 38 29665\n",
      "['Olympics' 'gold' 'olympic' 'competition'] 47 29667\n",
      "['Olympics' 'gold' 'medal' 'Winter'] 55 29671\n",
      "['Olympics' 'gold' 'medal' 'competition'] 53 29675\n",
      "['Olympics' 'athlete' 'olympic' 'medal'] 82 29686\n",
      "['Olympics' 'athlete' 'olympic' 'competition'] 38 29688\n",
      "['Olympics' 'athlete' 'medal' 'competition'] 36 29691\n",
      "['Olympics' 'olympic' 'medal' 'Winter'] 40 29697\n",
      "['Olympics' 'olympic' 'medal' 'competition'] 51 29700\n",
      "['Olympic' 'Games' 'gold' 'athlete'] 52 30653\n",
      "['Olympic' 'Games' 'gold' 'olympic'] 67 30654\n",
      "['Olympic' 'Games' 'athlete' 'olympic'] 55 30658\n",
      "['Olympic' 'Games' 'athlete' 'medal'] 61 30660\n",
      "['Olympic' 'Games' 'athlete' 'competition'] 42 30662\n",
      "['Olympic' 'Games' 'olympic' 'medal'] 75 30664\n",
      "['Olympic' 'Games' 'olympic' 'competition'] 42 30666\n",
      "['Olympic' 'Games' 'medal' 'competition'] 39 30672\n",
      "['Olympic' 'gold' 'athlete' 'olympic'] 53 30676\n",
      "['Olympic' 'gold' 'athlete' 'medal'] 66 30678\n",
      "['Olympic' 'gold' 'olympic' 'medal'] 90 30680\n",
      "['Olympic' 'gold' 'medal' 'Winter'] 37 30682\n",
      "['Olympic' 'athlete' 'olympic' 'medal'] 57 30686\n",
      "['Games' 'gold' 'athlete' 'olympic'] 46 32020\n",
      "['Games' 'gold' 'athlete' 'medal'] 58 32021\n",
      "['Games' 'gold' 'olympic' 'medal'] 79 32023\n",
      "['Games' 'gold' 'medal' 'competition'] 41 32026\n",
      "['Games' 'athlete' 'olympic' 'medal'] 51 32028\n",
      "['Games' 'olympic' 'medal' 'competition'] 38 32032\n",
      "['overall' 'gold' 'olympic' 'medal'] 39 32108\n",
      "['gold' 'athlete' 'olympic' 'medal'] 85 32507\n",
      "['gold' 'olympic' 'medal' 'Winter'] 41 32513\n",
      "['gold' 'olympic' 'medal' 'competition'] 49 32517\n",
      "['athlete' 'olympic' 'medal' 'competition'] 36 32722\n",
      "['Olympics' 'Olympic' 'Games' 'overall' 'gold'] 27 32789\n",
      "['Olympics' 'Olympic' 'Games' 'overall' 'medal'] 27 32791\n",
      "['Olympics' 'Olympic' 'Games' 'gold' 'athlete'] 40 32793\n",
      "['Olympics' 'Olympic' 'Games' 'gold' 'medal'] 68 32795\n",
      "['Olympics' 'Olympic' 'Games' 'athlete' 'olympic'] 44 32801\n",
      "['Olympics' 'Olympic' 'Games' 'athlete' 'medal'] 46 32803\n",
      "['Olympics' 'Olympic' 'Games' 'athlete' 'competition'] 30 32806\n",
      "['Olympics' 'Olympic' 'Games' 'olympic' 'competition'] 33 32810\n",
      "['Olympics' 'Olympic' 'Games' 'medal' 'Winter'] 27 32817\n",
      "['Olympics' 'Olympic' 'Games' 'medal' 'competition'] 29 32820\n",
      "['Olympics' 'Olympic' 'overall' 'gold' 'medal'] 29 32821\n",
      "['Olympics' 'Olympic' 'gold' 'athlete' 'olympic'] 44 32827\n",
      "['Olympics' 'Olympic' 'gold' 'athlete' 'medal'] 52 32829\n",
      "['Olympics' 'Olympic' 'gold' 'olympic' 'medal'] 73 32832\n",
      "['Olympics' 'Olympic' 'gold' 'olympic' 'competition'] 28 32834\n",
      "['Olympics' 'Olympic' 'gold' 'medal' 'Winter'] 33 32840\n",
      "['Olympics' 'Olympic' 'gold' 'medal' 'competition'] 29 32843\n",
      "['Olympics' 'Olympic' 'athlete' 'olympic' 'medal'] 49 32848\n",
      "['Olympics' 'Olympic' 'olympic' 'medal' 'competition'] 30 32854\n",
      "['Olympics' 'Games' 'overall' 'gold' 'medal'] 31 32860\n",
      "['Olympics' 'Games' 'gold' 'athlete' 'olympic'] 39 32866\n",
      "['Olympics' 'Games' 'gold' 'athlete' 'medal'] 45 32868\n",
      "['Olympics' 'Games' 'gold' 'olympic' 'medal'] 62 32870\n",
      "['Olympics' 'Games' 'gold' 'olympic' 'competition'] 29 32872\n",
      "['Olympics' 'Games' 'gold' 'medal' 'Winter'] 28 32876\n",
      "['Olympics' 'Games' 'gold' 'medal' 'competition'] 34 32879\n",
      "['Olympics' 'Games' 'athlete' 'olympic' 'medal'] 44 32884\n",
      "['Olympics' 'Games' 'olympic' 'medal' 'competition'] 33 32891\n",
      "['Olympics' 'track' 'gold' 'athlete' 'medal'] 28 32895\n",
      "['Olympics' 'track' 'gold' 'olympic' 'medal'] 26 32896\n",
      "['Olympics' 'overall' 'gold' 'olympic' 'medal'] 27 32897\n",
      "['Olympics' 'gold' 'victory' 'olympic' 'medal'] 26 32908\n",
      "['Olympics' 'gold' 'athlete' 'olympic' 'medal'] 66 32922\n",
      "['Olympics' 'gold' 'athlete' 'olympic' 'competition'] 27 32924\n",
      "['Olympics' 'gold' 'athlete' 'medal' 'competition'] 28 32927\n",
      "['Olympics' 'gold' 'olympic' 'medal' 'Winter'] 38 32934\n",
      "['Olympics' 'gold' 'olympic' 'medal' 'competition'] 43 32939\n",
      "['Olympics' 'athlete' 'olympic' 'medal' 'competition'] 32 32953\n",
      "['Olympic' 'Games' 'gold' 'athlete' 'olympic'] 39 33940\n",
      "['Olympic' 'Games' 'gold' 'olympic' 'medal'] 63 33942\n",
      "['Olympic' 'Games' 'athlete' 'olympic' 'medal'] 44 33949\n",
      "['Olympic' 'Games' 'athlete' 'medal' 'competition'] 29 33952\n",
      "['Olympic' 'Games' 'olympic' 'medal' 'competition'] 30 33956\n",
      "['Olympic' 'gold' 'athlete' 'olympic' 'medal'] 50 33966\n",
      "['Olympic' 'gold' 'olympic' 'medal' 'competition'] 29 33971\n",
      "['Games' 'gold' 'athlete' 'olympic' 'medal'] 44 35956\n",
      "['Games' 'gold' 'athlete' 'medal' 'competition'] 26 35958\n",
      "['Games' 'gold' 'olympic' 'medal' 'competition'] 31 35961\n",
      "['track' 'gold' 'athlete' 'olympic' 'medal'] 28 35999\n",
      "['gold' 'athlete' 'olympic' 'medal' 'competition'] 29 36192\n"
     ]
    }
   ],
   "source": [
    "objects_idx_with_concepts = np.flatnonzero(big_concept_object[useful_concepts].T.dot(np.ones(1000)))\n",
    "i = np.random.choice(objects_idx_with_concepts)\n",
    "\n",
    "print(names[i], i)\n",
    "print()\n",
    "print('New method')\n",
    "concepts = np.flatnonzero(big_concept_object[useful_concepts][:, i].toarray().ravel() * (length_concept[useful_concepts] >= 1))\n",
    "#if len(concepts) > 10:\n",
    "#    concepts = np.random.choice(concepts, size=20, replace=False)\n",
    "for j in concepts:\n",
    "    print(names_attribute[big_concept_attribute[useful_concepts][j].indices], j)\n",
    "    \n",
    "print()\n",
    "print(f'old method')\n",
    "concepts = np.flatnonzero(concept_object[:, i].toarray().ravel() * (length_concept > 1))\n",
    "\n",
    "for j in concepts:\n",
    "    print(names_attribute[concept_attribute[j].indices], concept_freq[j], j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True  True]\n",
      " [ True False  True]\n",
      " [ True  True False]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "a = np.array([0, 1, 2])\n",
    "dist = np.array([[0, 0.2, 0.7], [0.2, 0, 0.35], [0.7, 0.35, 0]])\n",
    "\n",
    "tau = 2\n",
    "adj = dist < tau\n",
    "for i in range(adj.shape[0]):\n",
    "    adj[i, i] = False\n",
    "adj # edge when nodes are similar, i.e. distance between them is less than treshold\n",
    "print(adj)\n",
    "\n",
    "G = nx.from_numpy_array(adj)\n",
    "nx.maximal_independent_set(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /Users/simondelarue/Documents/PhD/Research/Envs/COMEG/lib/python3.9/site-packages/pulp/apis/../solverdir/cbc/osx/64/cbc /var/folders/hb/p2nvp7cj1dg6y96zlm9vqb2c0000gn/T/28330518902f48c1a35a57e49cff4555-pulp.mps max timeMode elapsed branch printingOptions all solution /var/folders/hb/p2nvp7cj1dg6y96zlm9vqb2c0000gn/T/28330518902f48c1a35a57e49cff4555-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 6 COLUMNS\n",
      "At line 19 RHS\n",
      "At line 21 BOUNDS\n",
      "At line 25 ENDATA\n",
      "Problem MODEL has 1 rows, 3 columns and 3 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Continuous objective value is 1.95 - 0.00 seconds\n",
      "Cgl0004I processed model has 1 rows, 3 columns (3 integer (3 of which binary)) and 3 elements\n",
      "Cutoff increment increased from 1e-05 to 0.04995\n",
      "Cbc0038I Initial state - 0 integers unsatisfied sum - 0\n",
      "Cbc0038I Solution found of -1.95\n",
      "Cbc0038I Before mini branch and bound, 3 integers at bound fixed and 0 continuous\n",
      "Cbc0038I Mini branch and bound did not improve solution (0.01 seconds)\n",
      "Cbc0038I After 0.01 seconds - Feasibility pump exiting with objective of -1.95 - took 0.00 seconds\n",
      "Cbc0012I Integer solution of -1.95 found by feasibility pump after 0 iterations and 0 nodes (0.01 seconds)\n",
      "Cbc0001I Search completed - best objective -1.95, took 0 iterations and 0 nodes (0.01 seconds)\n",
      "Cbc0035I Maximum depth 0, 0 variables fixed on reduced cost\n",
      "Cuts at root node changed objective from -1.95 to -1.95\n",
      "Probing was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Gomory was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Knapsack was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "Clique was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "MixedIntegerRounding2 was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "FlowCover was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "TwoMirCuts was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "ZeroHalf was tried 0 times and created 0 cuts of which 0 were active after adding rounds of cuts (0.000 seconds)\n",
      "\n",
      "Result - Optimal solution found\n",
      "\n",
      "Objective value:                1.95000000\n",
      "Enumerated nodes:               0\n",
      "Total iterations:               0\n",
      "Time (CPU seconds):             0.00\n",
      "Time (Wallclock seconds):       0.01\n",
      "\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.02\n",
      "\n",
      "[(x_0, 1.0), (x_1, 0.0), (x_2, 1.0)]\n",
      "[0.9  0.55 1.05]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169956, 39777)\n"
     ]
    }
   ],
   "source": [
    "from pulp import LpVariable\n",
    "\n",
    "class Solver():\n",
    "    def __init__(self, concept_object, concept_attribute):\n",
    "        self.concept_object = concept_object\n",
    "        self.concept_attribute = concept_attribute\n",
    "        self.concept_idx = np.arange(0, self.concept_object.shape[0])\n",
    "        self.x = LpVariable.dicts(\"x\", \n",
    "                                indices = self.concept_idx, \n",
    "                                lowBound=0, upBound=1, \n",
    "                                cat='Integer', indexStart=[])\n",
    "        \n",
    "    \n",
    "    def init_variables(self):\n",
    "        # (i) maximize the average of the word embeddings of each set, (ii) minimize the total pairwise cosine similarity\n",
    "        #tfidf = TfIdf().fit_transform(self.concept_attribute)\n",
    "        w2v = \n",
    "        return tfidf.shape\n",
    "        \n",
    "solver = Solver(concept_object.tolil(), concept_attribute)\n",
    "res = solver.init_variables()\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solver():\n",
    "    def __init__(self, concept_object, concept_attribute):\n",
    "        self.concept_object = concept_object\n",
    "        self.concept_attribute = concept_attribute\n",
    "        self.concepts_idx = np.arange(0, self.concepts.shape[0])\n",
    "        self.x = pulp.LpVariable.dicts(\"x\", \n",
    "                                indices = self.concepts_idx, \n",
    "                                lowBound=0, upBound=1, \n",
    "                                cat='Integer', indexStart=[])\n",
    "    \n",
    "    def init_model_variables(self):\n",
    "\n",
    "        tfidf = TfIdf().fit_transform(self.concept_attribute)\n",
    "        for c in self.concepts:\n",
    "            \n",
    "            if metric == 'tf-idf':\n",
    "                tfidf_val = 0\n",
    "                gamma = 5\n",
    "                idx_row = [self.lattice.context.G2idx.get(obj) for obj in c[0]]\n",
    "                idx_col = [self.lattice.context.M2idx.get(attr) for attr in c[1]]\n",
    "                tfidf_val = self.lattice.context.I[idx_row, :][:, idx_col].sum() # fc.filter_transform(method='tf-idf', k=100) needs to be called by user\n",
    "                int_var.append(tfidf_val)\n",
    "                ext_var.append(np.exp(-len(c[1])/gamma)) # size of intent is stored in ext_var \n",
    "                #ext_var.append(0) # size of intent is stored in ext_var \n",
    "                #print(f'ext: {np.exp(-len(c[1])/gamma):.3f} - int: {tfidf_val:.3f} - sum: {(np.exp(-len(c[1])/gamma)+tfidf_val):.3f} - {c}')\n",
    "\n",
    "            else:\n",
    "                int_var.append(len(c[1]) / n_unique_attr)\n",
    "                # Size of graph induced by concept\n",
    "                attr_idxs = [self.lattice.context.G2idx.get(i) for i in c[0]]\n",
    "                g_concept = self.lattice.context.graph.adjacency_csr.T[attr_idxs]\n",
    "                n_right, n_left = g_concept.shape\n",
    "                m = g_concept.nnz\n",
    "                ext_var.append((n_right + n_left + m) / self.lattice.context.graph.size())\n",
    "\n",
    "        return ext_var, int_var\n",
    "    \n",
    "    def multi_obj_model(self, k: int = 5, metric: str = 'size'):\n",
    "        \"\"\"Build optmization multi-objective model with constraints, using weighted sum approach.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int, optional\n",
    "            Number of concepts to select, by default 5\n",
    "        metric : str\n",
    "            * 'size': Size of extent and intent. Variables are:\n",
    "                * Coverage of graph induced by the extent wrt the graph in the vicinity of the prediction\n",
    "                * Ratio between size of the intent and number of unique attributes\n",
    "            * 'tf-idf': Sum of `tf-idf` scores for each object-attribute pair\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ``pulp`` problem object.\n",
    "        \"\"\"        \n",
    "        # Variables are lengths of extent and intent of concepts\n",
    "        ext_var, int_var = self.init_model_variables(metric=metric)\n",
    "        \n",
    "        # Find subset of 5 concepts that maximize both lengths of extents and intents\n",
    "        step_size = 0.1\n",
    "        solutionTable = pd.DataFrame(columns=[\"alpha\", \"obj_value\"])\n",
    "        min_obj = np.inf\n",
    "\n",
    "        for alpha in np.arange(0, 1 + step_size, step_size):\n",
    "            # Model definition\n",
    "            prob = pulp.LpProblem(\"Best_concepts Multi objectives\", LpMaximize)\n",
    "            prob += alpha * pulp.lpSum([self.x[c] * ext_var[c] for c in self.concepts_idx]) \\\n",
    "                + (1 - alpha) * pulp.lpSum([self.x[c] * int_var[c] for c in self.concepts_idx])\n",
    "            prob += pulp.lpSum([self.x[c] for c in self.concepts_idx]) == k\n",
    "            if metric == 'size':\n",
    "                for c in self.concepts_idx:\n",
    "                    prob += self.x[c] * ext_var[c] <= 0.95\n",
    "                    prob += self.x[c] * int_var[c] <= 0.95\n",
    "            # Solving model\n",
    "            solution = prob.solve(PULP_CBC_CMD(msg=False))\n",
    "            solutionTable.loc[int(alpha*1/step_size)] = [alpha, pulp.value(prob.objective)]\n",
    "            \n",
    "            if pulp.value(prob.objective) <= min_obj:    \n",
    "                min_obj = pulp.value(prob.objective)\n",
    "                min_prob = prob\n",
    "\n",
    "        # Plot Pareto frontier\n",
    "        #fig, ax = plt.subplots(1, 1, figsize=(12, 7))\n",
    "        #print(solutionTable)\n",
    "        #plt.plot(solutionTable['alpha'], solutionTable['obj_value'], color='g')\n",
    "        #plt.xlabel('alpha')\n",
    "        #plt.ylabel('Objective value')\n",
    "        #plt.show()\n",
    "        # Save result img\n",
    "        #PATH_RES = os.path.join(os.getcwd(), 'data', 'goodreads_poetry', 'result')\n",
    "        #res = os.path.join(PATH_RES, 'img', f'LO_pareto_bc1d727746e210f315138932e0aacb11_13637887.eps')\n",
    "        #plt.tight_layout()\n",
    "        #plt.savefig(res)\n",
    "\n",
    "        return min_prob\n",
    "        \n",
    "    def model(self, k: int = 5, metric: str = 'size'):\n",
    "        \"\"\"Build optmization model with objective and constraints.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int, optional\n",
    "            Number of concepts to select, by default 5\n",
    "        metric : str\n",
    "            * 'size': Size of extent and intent\n",
    "            * 'tf-idf': Sum of `tf-idf` scores for each object-attribute pair\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ``pulp`` problem object.\n",
    "        \"\"\"        \n",
    "        # Initialize variables to optimize according to metric\n",
    "        ext_var, int_var = self.init_model_variables(metric=metric)\n",
    "\n",
    "        # Find subset of 5 concepts that maximize variable\n",
    "        prob = pulp.LpProblem(\"Best_concepts\", LpMaximize)\n",
    "        prob += pulp.lpSum([self.x[i] * (int_var[i] + ext_var[i]) for i in self.concepts_idx])\n",
    "        prob += pulp.lpSum([self.x[i] for i in self.concepts_idx]) == k\n",
    "        for i in self.concepts_idx:\n",
    "            prob += self.x[i] * ext_var[i] <= 0.95\n",
    "        \n",
    "        return prob\n",
    "\n",
    "    def solve(self, k: int = 5, metric: str = 'size', solver: object = PULP_CBC_CMD, msg: bool = False) -> list:\n",
    "        \"\"\"Solve optimization problem (default solver is CBC MILP).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int, optional\n",
    "            Number of concepts to select, by default 5\n",
    "        metric : str\n",
    "            * 'size': Size of extent and intent\n",
    "            * 'tf-idf': Sum of `tf-idf` scores for each object-attribute pair\n",
    "        msg : bool, optional\n",
    "            If `True`, print solver log in standard output, by default False\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            List of concepts maximizing optimization problem.\n",
    "        \"\"\"        \n",
    "        \n",
    "        # Solve optimization\n",
    "        if metric in ('size'):\n",
    "            prob = self.multi_obj_model(k=k, metric=metric)\n",
    "        elif metric == 'tf-idf':\n",
    "            prob = self.model(k=k, metric=metric)\n",
    "            prob.solve(solver(msg=msg))\n",
    "        \n",
    "        concept_idxs = np.array([int(v.name.split('_')[1]) for v in prob.variables() if v.varValue > 0])\n",
    "        scores = np.array([v.dj for v in prob.variables()])\n",
    "\n",
    "        return list(self.concepts[concept_idxs]), scores\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Implicit_recommandation-solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "COMEG",
   "language": "python",
   "name": "comeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
